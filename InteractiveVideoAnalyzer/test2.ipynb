{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b3d620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from deepface import DeepFace\n",
    "import os\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "INVENTORY_CSV = \"video_inventory.csv\" # The file with cam_path, screen_path, id\n",
    "OUTPUT_CSV = \"training_features.csv\"\n",
    "SAMPLE_RATE = 15  # Process 1 frame every 15 frames (approx 2 times per second)\n",
    "# ---------------------\n",
    "\n",
    "def extract_features(cam_path, screen_path, label):\n",
    "    # 1. Setup\n",
    "    cap_cam = cv2.VideoCapture(cam_path)\n",
    "    cap_scr = cv2.VideoCapture(screen_path)\n",
    "    \n",
    "    # We will average features over the whole video to create a \"Video Signature\"\n",
    "    # Or we can keep time-series data. For 100 videos, a \"Signature\" is safer to avoid overfitting.\n",
    "    \n",
    "    emotions_sum = {'angry': 0, 'disgust': 0, 'fear': 0, 'happy': 0, 'sad': 0, 'surprise': 0, 'neutral': 0}\n",
    "    screen_motion_sum = 0\n",
    "    frame_count = 0\n",
    "    valid_frames = 0\n",
    "    \n",
    "    prev_gray_scr = None\n",
    "    \n",
    "    while True:\n",
    "        ret_c, frame_c = cap_cam.read()\n",
    "        ret_s, frame_s = cap_scr.read()\n",
    "        \n",
    "        if not ret_c or not ret_s: break\n",
    "        \n",
    "        # Process every Nth frame\n",
    "        if frame_count % SAMPLE_RATE == 0:\n",
    "            try:\n",
    "                # A. FACE ANALYSIS\n",
    "                # We use the raw probability scores, not just the label\n",
    "                result = DeepFace.analyze(frame_c, actions=['emotion'], \n",
    "                                        enforce_detection=False, silent=True)\n",
    "                \n",
    "                if result:\n",
    "                    probs = result[0]['emotion'] # Returns dict {'angry': 0.02, 'happy': 99.0...}\n",
    "                    for key in emotions_sum:\n",
    "                        emotions_sum[key] += probs.get(key, 0)\n",
    "                    \n",
    "                # B. SCREEN ANALYSIS (Optical Flow / Commotion)\n",
    "                gray_s = cv2.cvtColor(frame_s, cv2.COLOR_BGR2GRAY)\n",
    "                gray_s = cv2.resize(gray_s, (224, 224)) # Resize for speed\n",
    "                \n",
    "                if prev_gray_scr is not None:\n",
    "                    diff = cv2.absdiff(prev_gray_scr, gray_s)\n",
    "                    score = np.sum(diff) / (224*224) # Normalize by size\n",
    "                    screen_motion_sum += score\n",
    "                \n",
    "                prev_gray_scr = gray_s\n",
    "                valid_frames += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                pass\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "    cap_cam.release()\n",
    "    cap_scr.release()\n",
    "    \n",
    "    if valid_frames == 0: return None\n",
    "    \n",
    "    # C. Normalize (Get Averages)\n",
    "    features = {}\n",
    "    for key, val in emotions_sum.items():\n",
    "        features[f\"face_{key}\"] = val / valid_frames\n",
    "        \n",
    "    features['screen_motion'] = screen_motion_sum / valid_frames\n",
    "    features['label'] = label\n",
    "    \n",
    "    return features\n",
    "\n",
    "# --- MAIN LOOP ---\n",
    "print(\"Extracting Features for Custom Training...\")\n",
    "df = pd.read_csv(INVENTORY_CSV)\n",
    "\n",
    "# Load labels if you have them (from your auto-labeling earlier)\n",
    "labels_df = pd.read_csv(\"labeled_dataset.csv\") \n",
    "# We merge them to make sure we have the 'label' column\n",
    "df = df.merge(labels_df[['id', 'label']], on='id', how='left')\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    print(f\"Processing ID {row['id']}...\", end=\"\")\n",
    "    \n",
    "    if pd.isna(row['label']):\n",
    "        print(\" -> SKIP (No Label)\")\n",
    "        continue\n",
    "        \n",
    "    feats = extract_features(row['cam_path'], row['screen_path'], row['label'])\n",
    "    \n",
    "    if feats:\n",
    "        feats['id'] = row['id']\n",
    "        all_data.append(feats)\n",
    "        print(\" -> Done\")\n",
    "    else:\n",
    "        print(\" -> Failed (Video Error)\")\n",
    "\n",
    "# Save\n",
    "train_df = pd.DataFrame(all_data)\n",
    "train_df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(\"-\" * 30)\n",
    "print(f\"Feature Extraction Complete. Saved to {OUTPUT_CSV}\")\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bb8fb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "     -------------------------------------- 294.9/294.9 kB 1.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\janak\\onedrive\\desktop\\videoanalyzer\\.venv\\lib\\site-packages (from seaborn) (2.2.6)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\janak\\onedrive\\desktop\\videoanalyzer\\.venv\\lib\\site-packages (from seaborn) (2.3.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\janak\\onedrive\\desktop\\videoanalyzer\\.venv\\lib\\site-packages (from seaborn) (3.10.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\janak\\onedrive\\desktop\\videoanalyzer\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\janak\\onedrive\\desktop\\videoanalyzer\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\janak\\onedrive\\desktop\\videoanalyzer\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\janak\\onedrive\\desktop\\videoanalyzer\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\janak\\onedrive\\desktop\\videoanalyzer\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\janak\\onedrive\\desktop\\videoanalyzer\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\janak\\onedrive\\desktop\\videoanalyzer\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\janak\\onedrive\\desktop\\videoanalyzer\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\janak\\onedrive\\desktop\\videoanalyzer\\.venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\janak\\onedrive\\desktop\\videoanalyzer\\.venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\janak\\onedrive\\desktop\\videoanalyzer\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdd43e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Custom Model Results ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        PASS       0.88      0.70      0.78        10\n",
      "        FAIL       0.77      0.91      0.83        11\n",
      "\n",
      "    accuracy                           0.81        21\n",
      "   macro avg       0.82      0.80      0.81        21\n",
      "weighted avg       0.82      0.81      0.81        21\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Load Data\n",
    "df = pd.read_csv(\"training_features.csv\")\n",
    "\n",
    "# 2. Prepare Features (X) and Labels (y)\n",
    "# We drop ID and Label from inputs\n",
    "X = df.drop(columns=['id', 'label'])\n",
    "y = df['label']\n",
    "\n",
    "# 3. Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. Train Custom Model\n",
    "# Random Forest is excellent for small datasets (100 rows) with complex features\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 5. Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"--- Custom Model Results ---\")\n",
    "print(classification_report(y_test, y_pred, target_names=['PASS', 'FAIL']))\n",
    "\n",
    "# 6. Novelty Visualization: Which features matter most?\n",
    "# This proves your thesis: \"Which emotions predict failure in Sri Lankan users?\"\n",
    "import numpy as np\n",
    "feature_importance = model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=feature_importance, y=feature_names)\n",
    "plt.title(\"Feature Importance: What predicts UI Failure?\")\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cc6d8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Video Pair...\n",
      "----------------------------------------\n",
      "ü§ñ AI Verdict:  FAIL (Buggy UI)\n",
      "üìä Confidence: 92.0%\n",
      "----------------------------------------\n",
      "üìù Diagnostics:\n",
      "   ‚Ä¢ Dominant Emotion: NEUTRAL\n",
      "   ‚Ä¢ Screen Activity:  6.84 (Motion Score)\n",
      "\n",
      "üö© Root Cause Analysis:\n",
      "   User reaction (neutral) deviates from the neutral baseline.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from deepface import DeepFace\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "TEST_CAM = \"dataset/cam72.mkv\"      # <--- Change to a test video\n",
    "TEST_SCREEN = \"dataset/screen72.mkv\"\n",
    "# ---------------------\n",
    "\n",
    "def predict_ui_quality(cam_path, screen_path, model):\n",
    "    print(f\"Analyzing Video Pair...\")\n",
    "    \n",
    "    # 1. Extract Features (Same logic as training)\n",
    "    cap_cam = cv2.VideoCapture(cam_path)\n",
    "    cap_scr = cv2.VideoCapture(screen_path)\n",
    "    \n",
    "    emotions_sum = {'angry': 0, 'disgust': 0, 'fear': 0, 'happy': 0, 'sad': 0, 'surprise': 0, 'neutral': 0}\n",
    "    screen_motion_sum = 0\n",
    "    valid_frames = 0\n",
    "    frame_count = 0\n",
    "    prev_gray_scr = None\n",
    "    \n",
    "    while True:\n",
    "        ret_c, frame_c = cap_cam.read()\n",
    "        ret_s, frame_s = cap_scr.read()\n",
    "        if not ret_c or not ret_s: break\n",
    "        \n",
    "        # Sample every 15 frames (approx 0.5 sec)\n",
    "        if frame_count % 15 == 0:\n",
    "            try:\n",
    "                # Face\n",
    "                result = DeepFace.analyze(frame_c, actions=['emotion'], enforce_detection=False, silent=True)\n",
    "                if result:\n",
    "                    probs = result[0]['emotion']\n",
    "                    for key in emotions_sum:\n",
    "                        emotions_sum[key] += probs.get(key, 0)\n",
    "                \n",
    "                # Screen\n",
    "                gray_s = cv2.cvtColor(frame_s, cv2.COLOR_BGR2GRAY)\n",
    "                gray_s = cv2.resize(gray_s, (224, 224))\n",
    "                if prev_gray_scr is not None:\n",
    "                    diff = cv2.absdiff(prev_gray_scr, gray_s)\n",
    "                    score = np.sum(diff) / (224*224)\n",
    "                    screen_motion_sum += score\n",
    "                prev_gray_scr = gray_s\n",
    "                valid_frames += 1\n",
    "            except: pass\n",
    "        frame_count += 1\n",
    "        \n",
    "    cap_cam.release()\n",
    "    cap_scr.release()\n",
    "    \n",
    "    if valid_frames == 0: return \"Error processing video\"\n",
    "\n",
    "    # 2. Normalize Features\n",
    "    features = {}\n",
    "    for key, val in emotions_sum.items():\n",
    "        features[f\"face_{key}\"] = val / valid_frames\n",
    "    features['screen_motion'] = screen_motion_sum / valid_frames\n",
    "    \n",
    "    # Create DataFrame for Model\n",
    "    input_df = pd.DataFrame([features])\n",
    "    \n",
    "    # Reorder columns to match training data exactly\n",
    "    # (We rely on the feature names from the trained model)\n",
    "    input_df = input_df[model.feature_names_in_]\n",
    "    \n",
    "    # 3. Predict\n",
    "    prediction = model.predict(input_df)[0]\n",
    "    probabilities = model.predict_proba(input_df)[0]\n",
    "    \n",
    "    # 4. Generate the \"Why?\" Explanation\n",
    "    result_text = \"PASS (Good UI)\" if prediction == 0 else \"FAIL (Buggy UI)\"\n",
    "    confidence = max(probabilities) * 100\n",
    "    \n",
    "    # Find the strongest emotion\n",
    "    dominant_emotion = max(emotions_sum, key=emotions_sum.get)\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "    print(f\"ü§ñ AI Verdict:  {result_text}\")\n",
    "    print(f\"üìä Confidence: {confidence:.1f}%\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"üìù Diagnostics:\")\n",
    "    print(f\"   ‚Ä¢ Dominant Emotion: {dominant_emotion.upper()}\")\n",
    "    print(f\"   ‚Ä¢ Screen Activity:  {features['screen_motion']:.2f} (Motion Score)\")\n",
    "    \n",
    "    if prediction == 1:\n",
    "        print(\"\\nüö© Root Cause Analysis:\")\n",
    "        if dominant_emotion == 'fear':\n",
    "            print(\"   User showed signs of ANXIETY/CONFUSION. The UI likely lacks clear instructions.\")\n",
    "        elif dominant_emotion == 'sad':\n",
    "            print(\"   User showed signs of DISAPPOINTMENT. The UI likely failed to meet expectations.\")\n",
    "        elif dominant_emotion == 'angry':\n",
    "            print(\"   User showed signs of FRUSTRATION. The UI likely has unresponsive elements.\")\n",
    "        else:\n",
    "            print(f\"   User reaction ({dominant_emotion}) deviates from the neutral baseline.\")\n",
    "\n",
    "# Run the Demo\n",
    "predict_ui_quality(TEST_CAM, TEST_SCREEN, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e7cbae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading YOLO from best.pt...\n",
      "------------------------------------------------------------\n",
      "TIME       | EMOTION      | DETECTED UI ELEMENT\n",
      "------------------------------------------------------------\n",
      "0:00:06    | sad          | image\n",
      "0:00:08    | fear         | button\n",
      "0:00:10    | fear         | button\n",
      "0:00:12    | fear         | button\n",
      "0:00:15    | fear         | image\n",
      "0:00:16    | fear         | image\n",
      "0:00:17    | fear         | button\n",
      "0:00:18    | fear         | image\n",
      "0:00:19    | fear         | image\n",
      "0:00:20    | fear         | image\n",
      "0:00:21    | fear         | image\n",
      "0:00:22    | fear         | button\n",
      "0:00:23    | fear         | image\n",
      "0:00:24    | fear         | image\n",
      "0:00:25    | fear         | image\n",
      "0:00:26    | fear         | button\n",
      "0:00:27    | fear         | image\n",
      "0:00:28    | fear         | image\n",
      "0:00:29    | fear         | image\n",
      "0:00:30    | fear         | image\n",
      "0:00:31    | fear         | button\n",
      "0:00:32    | fear         | button\n",
      "0:00:34    | sad          | image\n",
      "0:00:52    | sad          | image\n",
      "0:00:53    | sad          | image\n",
      "0:00:54    | sad          | image\n",
      "0:00:55    | sad          | image\n",
      "0:00:56    | sad          | image\n",
      "0:01:15    | sad          | image\n",
      "0:01:20    | sad          | image\n",
      "0:01:21    | sad          | button\n",
      "0:01:23    | sad          | image\n",
      "0:01:24    | sad          | button\n",
      "0:01:27    | sad          | image\n",
      "0:01:28    | sad          | image\n",
      "0:01:30    | sad          | image\n",
      "0:01:41    | sad          | button\n",
      "0:01:45    | sad          | image\n",
      "0:01:46    | fear         | image\n",
      "0:01:47    | fear         | image\n",
      "0:01:48    | fear         | image\n",
      "0:01:49    | fear         | image\n",
      "0:01:50    | fear         | image\n",
      "0:01:51    | fear         | image\n",
      "0:01:52    | fear         | image\n",
      "0:01:53    | fear         | image\n",
      "0:01:54    | fear         | image\n",
      "0:01:55    | fear         | image\n",
      "0:01:56    | fear         | image\n",
      "0:01:57    | fear         | image\n",
      "0:01:58    | fear         | button\n",
      "0:01:59    | sad          | button\n",
      "0:02:00    | sad          | button\n",
      "0:02:01    | fear         | image\n",
      "0:02:04    | sad          | image\n",
      "0:02:09    | sad          | image\n",
      "0:02:16    | sad          | image\n",
      "0:02:30    | sad          | image\n",
      "0:03:00    | fear         | image\n",
      "0:03:01    | fear         | image\n",
      "------------------------------------------------------------\n",
      "Forensic Report Saved to bug_report.csv\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from deepface import DeepFace\n",
    "from ultralytics import YOLO\n",
    "import datetime\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "CAM_VIDEO = \"dataset/cam47.mkv\"       # User Face\n",
    "SCREEN_VIDEO = \"dataset/screen47.mkv\" # Screen Recording\n",
    "YOLO_MODEL = \"best.pt\"                # Your trained UI detector\n",
    "OUTPUT_REPORT = \"bug_report.csv\"\n",
    "# ---------------------\n",
    "\n",
    "def format_time(seconds):\n",
    "    return str(datetime.timedelta(seconds=int(seconds)))\n",
    "\n",
    "def forensic_analysis(cam_path, screen_path, yolo_path):\n",
    "    print(f\"Loading YOLO from {yolo_path}...\")\n",
    "    try:\n",
    "        yolo = YOLO(yolo_path)\n",
    "    except:\n",
    "        print(\"Error: Could not load YOLO model. Check path.\")\n",
    "        return\n",
    "\n",
    "    cap_cam = cv2.VideoCapture(cam_path)\n",
    "    cap_scr = cv2.VideoCapture(screen_path)\n",
    "    \n",
    "    fps = cap_cam.get(cv2.CAP_PROP_FPS)\n",
    "    if fps == 0: fps = 30\n",
    "    \n",
    "    # We only care about \"Bad\" emotions\n",
    "    triggers = ['angry', 'disgust', 'fear', 'sad']\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'TIME':<10} | {'EMOTION':<12} | {'DETECTED UI ELEMENT'}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    bug_log = []\n",
    "    frame_count = 0\n",
    "    \n",
    "    while True:\n",
    "        # Check 1 frame every second (to be fast)\n",
    "        frames_to_skip = int(fps) \n",
    "        cap_cam.set(cv2.CAP_PROP_POS_FRAMES, frame_count)\n",
    "        \n",
    "        ret_c, frame_c = cap_cam.read()\n",
    "        if not ret_c: break\n",
    "        \n",
    "        current_time = frame_count / fps\n",
    "        \n",
    "        try:\n",
    "            # 1. Check Face\n",
    "            result = DeepFace.analyze(frame_c, actions=['emotion'], \n",
    "                                    enforce_detection=False, silent=True)\n",
    "            \n",
    "            if result:\n",
    "                emotion = result[0]['dominant_emotion']\n",
    "                \n",
    "                # 2. If Bad Emotion Detected -> Check Screen\n",
    "                if emotion in triggers:\n",
    "                    # Sync Screen Video\n",
    "                    cap_scr.set(cv2.CAP_PROP_POS_MSEC, current_time * 1000)\n",
    "                    ret_s, frame_s = cap_scr.read()\n",
    "                    \n",
    "                    if ret_s:\n",
    "                        # 3. Run YOLO on this specific screen frame\n",
    "                        yolo_results = yolo(frame_s, verbose=False)\n",
    "                        \n",
    "                        detected_ui = \"Unknown UI Area\"\n",
    "                        \n",
    "                        # Get the UI element with highest confidence\n",
    "                        for r in yolo_results:\n",
    "                            if len(r.boxes) > 0:\n",
    "                                # Just pick the first/most confident box\n",
    "                                cls_id = int(r.boxes.cls[0])\n",
    "                                detected_ui = yolo.names[cls_id]\n",
    "                                break\n",
    "                        \n",
    "                        # Print Log\n",
    "                        timestamp = format_time(current_time)\n",
    "                        print(f\"{timestamp:<10} | {emotion:<12} | {detected_ui}\")\n",
    "                        \n",
    "                        bug_log.append({\n",
    "                            \"timestamp\": timestamp,\n",
    "                            \"emotion\": emotion,\n",
    "                            \"ui_element\": detected_ui\n",
    "                        })\n",
    "                        \n",
    "        except Exception as e:\n",
    "            pass\n",
    "            \n",
    "        frame_count += frames_to_skip\n",
    "\n",
    "    cap_cam.release()\n",
    "    cap_scr.release()\n",
    "    \n",
    "    # Save to CSV\n",
    "    if bug_log:\n",
    "        pd.DataFrame(bug_log).to_csv(OUTPUT_REPORT, index=False)\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"Forensic Report Saved to {OUTPUT_REPORT}\")\n",
    "    else:\n",
    "        print(\"No frustration detected.\")\n",
    "\n",
    "# Run it\n",
    "forensic_analysis(CAM_VIDEO, SCREEN_VIDEO, YOLO_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94aed89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading YOLO from best.pt...\n",
      "Generating Video (8889 frames)... This may take a moment.\n",
      "Processed 100/8889 frames...\n",
      "Processed 200/8889 frames...\n",
      "Processed 300/8889 frames...\n",
      "Processed 400/8889 frames...\n",
      "Processed 500/8889 frames...\n",
      "Processed 600/8889 frames...\n",
      "Processed 700/8889 frames...\n",
      "Processed 800/8889 frames...\n",
      "Processed 900/8889 frames...\n",
      "Processed 1000/8889 frames...\n",
      "Processed 1100/8889 frames...\n",
      "Processed 1200/8889 frames...\n",
      "Processed 1300/8889 frames...\n",
      "Processed 1400/8889 frames...\n",
      "Processed 1500/8889 frames...\n",
      "Processed 1600/8889 frames...\n",
      "Processed 1700/8889 frames...\n",
      "Processed 1800/8889 frames...\n",
      "Processed 1900/8889 frames...\n",
      "Processed 2000/8889 frames...\n",
      "Processed 2100/8889 frames...\n",
      "Processed 2200/8889 frames...\n",
      "Processed 2300/8889 frames...\n",
      "Processed 2400/8889 frames...\n",
      "Processed 2500/8889 frames...\n",
      "Processed 2600/8889 frames...\n",
      "Processed 2700/8889 frames...\n",
      "Processed 2800/8889 frames...\n",
      "Processed 2900/8889 frames...\n",
      "Processed 3000/8889 frames...\n",
      "Processed 3100/8889 frames...\n",
      "Processed 3200/8889 frames...\n",
      "Processed 3300/8889 frames...\n",
      "Processed 3400/8889 frames...\n",
      "Processed 3500/8889 frames...\n",
      "Processed 3600/8889 frames...\n",
      "Processed 3700/8889 frames...\n",
      "Processed 3800/8889 frames...\n",
      "Processed 3900/8889 frames...\n",
      "Processed 4000/8889 frames...\n",
      "Processed 4100/8889 frames...\n",
      "Processed 4200/8889 frames...\n",
      "Processed 4300/8889 frames...\n",
      "Processed 4400/8889 frames...\n",
      "Processed 4500/8889 frames...\n",
      "Processed 4600/8889 frames...\n",
      "Processed 4700/8889 frames...\n",
      "Processed 4800/8889 frames...\n",
      "Processed 4900/8889 frames...\n",
      "Processed 5000/8889 frames...\n",
      "Processed 5100/8889 frames...\n",
      "Processed 5200/8889 frames...\n",
      "Processed 5300/8889 frames...\n",
      "Processed 5400/8889 frames...\n",
      "Processed 5500/8889 frames...\n",
      "Processed 5600/8889 frames...\n",
      "Processed 5700/8889 frames...\n",
      "Processed 5800/8889 frames...\n",
      "Processed 5900/8889 frames...\n",
      "Processed 6000/8889 frames...\n",
      "Processed 6100/8889 frames...\n",
      "Processed 6200/8889 frames...\n",
      "Processed 6300/8889 frames...\n",
      "Processed 6400/8889 frames...\n",
      "Processed 6500/8889 frames...\n",
      "Processed 6600/8889 frames...\n",
      "Processed 6700/8889 frames...\n",
      "Processed 6800/8889 frames...\n",
      "Processed 6900/8889 frames...\n",
      "Processed 7000/8889 frames...\n",
      "Processed 7100/8889 frames...\n",
      "Processed 7200/8889 frames...\n",
      "Processed 7300/8889 frames...\n",
      "Processed 7400/8889 frames...\n",
      "Processed 7500/8889 frames...\n",
      "Processed 7600/8889 frames...\n",
      "Processed 7700/8889 frames...\n",
      "Processed 7800/8889 frames...\n",
      "Processed 7900/8889 frames...\n",
      "Processed 8000/8889 frames...\n",
      "Processed 8100/8889 frames...\n",
      "Processed 8200/8889 frames...\n",
      "Processed 8300/8889 frames...\n",
      "Processed 8400/8889 frames...\n",
      "Processed 8500/8889 frames...\n",
      "Processed 8600/8889 frames...\n",
      "Processed 8700/8889 frames...\n",
      "Processed 8800/8889 frames...\n",
      "--------------------------------------------------\n",
      "DONE! Video saved to: final_forensic_evidence3.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from deepface import DeepFace\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "CAM_VIDEO = \"dataset/cam5.mp4\"       \n",
    "SCREEN_VIDEO = \"dataset/screen5.mp4\" \n",
    "YOLO_MODEL = \"best.pt\"                \n",
    "OUTPUT_VIDEO = \"final_forensic_evidence3.mp4\"\n",
    "# ---------------------\n",
    "\n",
    "def create_forensic_video(cam_path, screen_path, yolo_path, output_path):\n",
    "    print(f\"Loading YOLO from {yolo_path}...\")\n",
    "    try:\n",
    "        yolo = YOLO(yolo_path)\n",
    "    except:\n",
    "        print(\"Error: Check YOLO path.\")\n",
    "        return\n",
    "\n",
    "    cap_cam = cv2.VideoCapture(cam_path)\n",
    "    cap_scr = cv2.VideoCapture(screen_path)\n",
    "    \n",
    "    # Get Screen Video Properties\n",
    "    width = int(cap_scr.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap_scr.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap_scr.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap_scr.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Setup Video Writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    # Triggers for \"Bad UI\"\n",
    "    triggers = ['angry', 'disgust', 'fear', 'sad']\n",
    "    \n",
    "    print(f\"Generating Video ({total_frames} frames)... This may take a moment.\")\n",
    "    \n",
    "    current_emotion = \"neutral\"\n",
    "    current_ui_box = None\n",
    "    current_ui_label = \"\"\n",
    "    \n",
    "    frame_idx = 0\n",
    "    \n",
    "    while True:\n",
    "        ret_s, frame_scr = cap_scr.read()\n",
    "        if not ret_s: break\n",
    "        \n",
    "        # We need to sync the webcam (cam might have different FPS, so we map by time)\n",
    "        current_time_ms = cap_scr.get(cv2.CAP_PROP_POS_MSEC)\n",
    "        cap_cam.set(cv2.CAP_PROP_POS_MSEC, current_time_ms)\n",
    "        ret_c, frame_cam = cap_cam.read()\n",
    "        \n",
    "        # OPTIMIZATION: Check emotion only once every 15 frames (0.5 seconds)\n",
    "        # We hold the emotion/box state constant in between checks to make the video smooth.\n",
    "        if frame_idx % 15 == 0 and ret_c:\n",
    "            try:\n",
    "                result = DeepFace.analyze(frame_cam, actions=['emotion'], \n",
    "                                        enforce_detection=False, silent=True)\n",
    "                if result:\n",
    "                    current_emotion = result[0]['dominant_emotion']\n",
    "                    \n",
    "                    # If Bad Emotion -> Find the Culprit on Screen\n",
    "                    if current_emotion in triggers:\n",
    "                        # Run YOLO on this screen frame\n",
    "                        results = yolo(frame_scr, verbose=False)\n",
    "                        \n",
    "                        # Reset box\n",
    "                        current_ui_box = None\n",
    "                        current_ui_label = \"\"\n",
    "                        \n",
    "                        # Pick the most confident detection\n",
    "                        for r in results:\n",
    "                            if len(r.boxes) > 0:\n",
    "                                box = r.boxes[0] # Top 1\n",
    "                                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                                cls_id = int(box.cls[0])\n",
    "                                \n",
    "                                current_ui_box = (int(x1), int(y1), int(x2), int(y2))\n",
    "                                current_ui_label = yolo.names[cls_id]\n",
    "                                break\n",
    "                    else:\n",
    "                        current_ui_box = None # Clear box if user is happy/neutral\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # --- DRAWING ON FRAME ---\n",
    "        \n",
    "        # If we have a detected failure case active\n",
    "        if current_ui_box is not None:\n",
    "            # 1. Draw Red Box around the UI element\n",
    "            x1, y1, x2, y2 = current_ui_box\n",
    "            cv2.rectangle(frame_scr, (x1, y1), (x2, y2), (0, 0, 255), 4)\n",
    "            \n",
    "            # 2. Draw \"Error Header\"\n",
    "            # Semi-transparent bar at the top\n",
    "            overlay = frame_scr.copy()\n",
    "            cv2.rectangle(overlay, (0, 0), (width, 80), (0, 0, 255), -1)\n",
    "            frame_scr = cv2.addWeighted(overlay, 0.3, frame_scr, 0.7, 0)\n",
    "            \n",
    "            # 3. Add Text: \"USER FEAR: FIX BUTTON\"\n",
    "            text = f\"USER {current_emotion.upper()}: FIX {current_ui_label.upper()}\"\n",
    "            cv2.putText(frame_scr, text, (20, 50), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)\n",
    "            \n",
    "            # 4. Add Label near the box\n",
    "            cv2.putText(frame_scr, \"BUG SOURCE\", (x1, y1-10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "            \n",
    "        else:\n",
    "            # Optional: Show \"Pass\" status slightly\n",
    "            cv2.putText(frame_scr, f\"User Status: {current_emotion}\", (20, 40), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        out.write(frame_scr)\n",
    "        frame_idx += 1\n",
    "        \n",
    "        if frame_idx % 100 == 0:\n",
    "            print(f\"Processed {frame_idx}/{total_frames} frames...\")\n",
    "\n",
    "    cap_cam.release()\n",
    "    cap_scr.release()\n",
    "    out.release()\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"DONE! Video saved to: {output_path}\")\n",
    "\n",
    "# Run it\n",
    "create_forensic_video(CAM_VIDEO, SCREEN_VIDEO, YOLO_MODEL, OUTPUT_VIDEO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6310402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\Interactive Video Analyzer\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Loading YOLO from best.pt...\n",
      "Generating Video (5441 frames)... This may take a moment.\n",
      "Processed 100/5441 frames...\n",
      "Processed 200/5441 frames...\n",
      "Processed 300/5441 frames...\n",
      "Processed 400/5441 frames...\n",
      "Processed 500/5441 frames...\n",
      "Processed 600/5441 frames...\n",
      "Processed 700/5441 frames...\n",
      "Processed 800/5441 frames...\n",
      "Processed 900/5441 frames...\n",
      "Processed 1000/5441 frames...\n",
      "Processed 1100/5441 frames...\n",
      "Processed 1200/5441 frames...\n",
      "Processed 1300/5441 frames...\n",
      "Processed 1400/5441 frames...\n",
      "Processed 1500/5441 frames...\n",
      "Processed 1600/5441 frames...\n",
      "Processed 1700/5441 frames...\n",
      "Processed 1800/5441 frames...\n",
      "Processed 1900/5441 frames...\n",
      "Processed 2000/5441 frames...\n",
      "Processed 2100/5441 frames...\n",
      "Processed 2200/5441 frames...\n",
      "Processed 2300/5441 frames...\n",
      "Processed 2400/5441 frames...\n",
      "Processed 2500/5441 frames...\n",
      "Processed 2600/5441 frames...\n",
      "Processed 2700/5441 frames...\n",
      "Processed 2800/5441 frames...\n",
      "Processed 2900/5441 frames...\n",
      "Processed 3000/5441 frames...\n",
      "Processed 3100/5441 frames...\n",
      "Processed 3200/5441 frames...\n",
      "Processed 3300/5441 frames...\n",
      "Processed 3400/5441 frames...\n",
      "Processed 3500/5441 frames...\n",
      "Processed 3600/5441 frames...\n",
      "Processed 3700/5441 frames...\n",
      "Processed 3800/5441 frames...\n",
      "Processed 3900/5441 frames...\n",
      "Processed 4000/5441 frames...\n",
      "Processed 4100/5441 frames...\n",
      "Processed 4200/5441 frames...\n",
      "Processed 4300/5441 frames...\n",
      "Processed 4400/5441 frames...\n",
      "Processed 4500/5441 frames...\n",
      "Processed 4600/5441 frames...\n",
      "Processed 4700/5441 frames...\n",
      "Processed 4800/5441 frames...\n",
      "Processed 4900/5441 frames...\n",
      "Processed 5000/5441 frames...\n",
      "Processed 5100/5441 frames...\n",
      "Processed 5200/5441 frames...\n",
      "Processed 5300/5441 frames...\n",
      "Processed 5400/5441 frames...\n",
      "--------------------------------------------------\n",
      "DONE!\n",
      "Video saved to: final_forensic_evidence.mp4\n",
      "JSON report saved to: forensic_report.json\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from deepface import DeepFace\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import json  # <--- Added for JSON support\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "CAM_VIDEO = \"dataset/cam5.mkv\"       \n",
    "SCREEN_VIDEO = \"dataset/screen5.mkv\" \n",
    "YOLO_MODEL = \"best.pt\"                \n",
    "OUTPUT_VIDEO = \"final_forensic_evidence1.mp4\"\n",
    "OUTPUT_JSON = \"forensic_report1.json\" # <--- New output file\n",
    "# ---------------------\n",
    "\n",
    "def create_forensic_video(cam_path, screen_path, yolo_path, output_path, json_path):\n",
    "    print(f\"Loading YOLO from {yolo_path}...\")\n",
    "    try:\n",
    "        yolo = YOLO(yolo_path)\n",
    "    except:\n",
    "        print(\"Error: Check YOLO path.\")\n",
    "        return\n",
    "\n",
    "    cap_cam = cv2.VideoCapture(cam_path)\n",
    "    cap_scr = cv2.VideoCapture(screen_path)\n",
    "    \n",
    "    width = int(cap_scr.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap_scr.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap_scr.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap_scr.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    triggers = ['angry', 'disgust', 'fear', 'sad']\n",
    "    \n",
    "    # --- JSON TRACKING ---\n",
    "    timeline_data = [] # List to store every flagged event\n",
    "    \n",
    "    print(f\"Generating Video ({total_frames} frames)... This may take a moment.\")\n",
    "    \n",
    "    current_emotion = \"neutral\"\n",
    "    current_ui_box = None\n",
    "    current_ui_label = \"\"\n",
    "    frame_idx = 0\n",
    "    \n",
    "    while True:\n",
    "        ret_s, frame_scr = cap_scr.read()\n",
    "        if not ret_s: break\n",
    "        \n",
    "        current_time_ms = cap_scr.get(cv2.CAP_PROP_POS_MSEC)\n",
    "        cap_cam.set(cv2.CAP_PROP_POS_MSEC, current_time_ms)\n",
    "        ret_c, frame_cam = cap_cam.read()\n",
    "        \n",
    "        if frame_idx % 15 == 0 and ret_c:\n",
    "            try:\n",
    "                result = DeepFace.analyze(frame_cam, actions=['emotion'], \n",
    "                                        enforce_detection=False, silent=True)\n",
    "                if result:\n",
    "                    current_emotion = result[0]['dominant_emotion']\n",
    "                    \n",
    "                    if current_emotion in triggers:\n",
    "                        results = yolo(frame_scr, verbose=False)\n",
    "                        current_ui_box = None\n",
    "                        current_ui_label = \"\"\n",
    "                        \n",
    "                        for r in results:\n",
    "                            if len(r.boxes) > 0:\n",
    "                                box = r.boxes[0]\n",
    "                                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                                cls_id = int(box.cls[0])\n",
    "                                \n",
    "                                current_ui_box = (int(x1), int(y1), int(x2), int(y2))\n",
    "                                current_ui_label = yolo.names[cls_id]\n",
    "                                \n",
    "                                # --- CAPTURE JSON DATA ---\n",
    "                                event = {\n",
    "                                    \"frame\": frame_idx,\n",
    "                                    \"timestamp_ms\": round(current_time_ms, 2),\n",
    "                                    \"emotion\": current_emotion,\n",
    "                                    \"ui_element\": current_ui_label,\n",
    "                                    \"bounding_box\": {\"x1\": int(x1), \"y1\": int(y1), \"x2\": int(x2), \"y2\": int(y2)}\n",
    "                                }\n",
    "                                timeline_data.append(event)\n",
    "                                break\n",
    "                    else:\n",
    "                        current_ui_box = None \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # Drawing logic (kept same as your original)\n",
    "        if current_ui_box is not None:\n",
    "            x1, y1, x2, y2 = current_ui_box\n",
    "            cv2.rectangle(frame_scr, (x1, y1), (x2, y2), (0, 0, 255), 4)\n",
    "            overlay = frame_scr.copy()\n",
    "            cv2.rectangle(overlay, (0, 0), (width, 80), (0, 0, 255), -1)\n",
    "            frame_scr = cv2.addWeighted(overlay, 0.3, frame_scr, 0.7, 0)\n",
    "            text = f\"USER {current_emotion.upper()}: FIX {current_ui_label.upper()}\"\n",
    "            cv2.putText(frame_scr, text, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)\n",
    "\n",
    "        out.write(frame_scr)\n",
    "        frame_idx += 1\n",
    "        \n",
    "        if frame_idx % 100 == 0:\n",
    "            print(f\"Processed {frame_idx}/{total_frames} frames...\")\n",
    "\n",
    "    # --- SAVE JSON FILE ---\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump({\n",
    "            \"video_source\": cam_path,\n",
    "            \"total_frames\": total_frames,\n",
    "            \"events_detected\": len(timeline_data),\n",
    "            \"timeline\": timeline_data\n",
    "        }, f, indent=4)\n",
    "\n",
    "    cap_cam.release()\n",
    "    cap_scr.release()\n",
    "    out.release()\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"DONE!\")\n",
    "    print(f\"Video saved to: {output_path}\")\n",
    "    print(f\"JSON report saved to: {json_path}\")\n",
    "\n",
    "# Run it\n",
    "create_forensic_video(CAM_VIDEO, SCREEN_VIDEO, YOLO_MODEL, OUTPUT_VIDEO, OUTPUT_JSON)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
